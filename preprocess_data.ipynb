{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "from pytz import timezone\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Connect to database\n",
    "    connection = psycopg2.connect(\n",
    "        user=\"user\",\n",
    "        port=\"port\",\n",
    "        host=\"localhost\",\n",
    "        database=\"name\"\n",
    "    )\n",
    "    \n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    queries = [\n",
    "        \"SELECT * FROM sentiment_data_aapl;\",\n",
    "        \"SELECT * FROM sentiment_data_amzn;\",\n",
    "        \"SELECT * FROM sentiment_data_msft;\",\n",
    "        \"SELECT * FROM sentiment_data_nvidia;\"\n",
    "    ]\n",
    "    \n",
    "    aapl_data, amzn_data, msft_data, nvidia_data = None, None, None, None\n",
    "    \n",
    "    # Execute the queries and fetch data\n",
    "    cursor.execute(queries[0])\n",
    "    aapl_data = cursor.fetchall()\n",
    "\n",
    "    cursor.execute(queries[1])\n",
    "    amzn_data = cursor.fetchall()\n",
    "    \n",
    "    cursor.execute(queries[2])\n",
    "    msft_data = cursor.fetchall()\n",
    "\n",
    "    cursor.execute(queries[3])\n",
    "    nvidia_data = cursor.fetchall()\n",
    "    \n",
    "except Exception as error:\n",
    "    print(f\"Failed to fetch records: {error}\")\n",
    "\n",
    "finally:\n",
    "    # Close the connection\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"Connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       January 8, 2009 Thursday\n",
       "1         January 28, 2009 Wednesday 2:36 PM EST\n",
       "2            January 2, 2009 Friday 12:15 PM EST\n",
       "3            January 12, 2009 Monday 9:01 AM EST\n",
       "4         January 14, 2009 Wednesday 4:17 PM EST\n",
       "                          ...                   \n",
       "33430    January 12, 2011 Wednesday 09:16 AM EST\n",
       "33431        January 14, 2011 Friday 9:32 AM GMT\n",
       "33432                     January 7, 2011 Friday\n",
       "33433      January 5, 2011 Wednesday 7:00 PM GMT\n",
       "33434     January 12, 2011 Wednesday 8:34 AM GMT\n",
       "Name: Time_Published, Length: 33435, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvidia_data[\"Time_Published\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rithvikprakki/anaconda3/lib/python3.10/site-packages/dateutil/parser/_parser.py:1207: UnknownTimezoneWarning: tzname CET identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m df \u001b[39min\u001b[39;00m [aapl_data, amzn_data, msft_data, nvidia_data]:\n\u001b[1;32m     20\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mCleaned_Date\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mTime_Published\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(remove_extras)\n\u001b[0;32m---> 21\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mDatetime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mCleaned_Date\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(to_datetime)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Now each DataFrame has a 'Datetime' column that should contain datetime objects\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4521\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4525\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4526\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4527\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4529\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4630\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1077\u001b[0m             values,\n\u001b[1;32m   1078\u001b[0m             f,\n\u001b[1;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[45], line 13\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(date_str)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39;49mto_datetime(date_str, errors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcoerce\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     14\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     15\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not convert to datetime: \u001b[39m\u001b[39m{\u001b[39;00mdate_str\u001b[39m}\u001b[39;00m\u001b[39m, error: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:1084\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1082\u001b[0m         result \u001b[39m=\u001b[39m convert_listlike(argc, \u001b[39mformat\u001b[39m)\n\u001b[1;32m   1083\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1084\u001b[0m     result \u001b[39m=\u001b[39m convert_listlike(np\u001b[39m.\u001b[39;49marray([arg]), \u001b[39mformat\u001b[39;49m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, \u001b[39mbool\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, np\u001b[39m.\u001b[39mbool_):\n\u001b[1;32m   1086\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mbool\u001b[39m(result)  \u001b[39m# TODO: avoid this kludge.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:449\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    446\u001b[0m arg \u001b[39m=\u001b[39m ensure_object(arg)\n\u001b[1;32m    448\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 449\u001b[0m     \u001b[39mformat\u001b[39m \u001b[39m=\u001b[39m _guess_datetime_format_for_array(arg, dayfirst\u001b[39m=\u001b[39;49mdayfirst)\n\u001b[1;32m    451\u001b[0m \u001b[39m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmixed\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:137\u001b[0m, in \u001b[0;36m_guess_datetime_format_for_array\u001b[0;34m(arr, dayfirst)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m (first_non_null \u001b[39m:=\u001b[39m tslib\u001b[39m.\u001b[39mfirst_non_null(arr)) \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(first_non_nan_element \u001b[39m:=\u001b[39m arr[first_non_null]) \u001b[39mis\u001b[39;00m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    136\u001b[0m         \u001b[39m# GH#32264 np.str_ object\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m         guessed_format \u001b[39m=\u001b[39m guess_datetime_format(\n\u001b[1;32m    138\u001b[0m             first_non_nan_element, dayfirst\u001b[39m=\u001b[39;49mdayfirst\n\u001b[1;32m    139\u001b[0m         )\n\u001b[1;32m    140\u001b[0m         \u001b[39mif\u001b[39;00m guessed_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m             \u001b[39mreturn\u001b[39;00m guessed_format\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/tslibs/parsing.pyx:957\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.guess_datetime_format\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/tslibs/parsing.pyx:1016\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing._fill_token\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/re.py:200\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearch\u001b[39m(pattern, string, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m    198\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\u001b[39m.\u001b[39;49msearch(string)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to remove days of the week, AM/PM, and timezones from date string\n",
    "def remove_extras(date_str):\n",
    "    if pd.isna(date_str) or date_str is None:\n",
    "        return None\n",
    "    cleaned_date = re.sub(r'(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday|EST|EDT|PST|PDT|GMT|AM|PM)', '', date_str).strip()\n",
    "    return cleaned_date\n",
    "\n",
    "# Function to convert cleaned date string to datetime object\n",
    "def to_datetime(date_str):\n",
    "    if pd.isna(date_str) or date_str is None:\n",
    "        return None\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(f\"Could not convert to datetime: {date_str}, error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Remove extras and convert to datetime for each dataframe\n",
    "for df in [aapl_data, amzn_data, msft_data, nvidia_data]:\n",
    "    df['Cleaned_Date'] = df['Time_Published'].apply(remove_extras)\n",
    "    df['Datetime'] = df['Cleaned_Date'].apply(to_datetime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert to datetime: July 2, 2007 Issue, error: unconverted data remains:  Issue\n",
      "Could not convert to datetime: June 2, 2008 Issue, error: unconverted data remains:  Issue\n"
     ]
    }
   ],
   "source": [
    "def convert_to_est_datetime(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return None\n",
    "    \n",
    "    # Remove day names\n",
    "    date_str = re.sub(r'(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday)', '', date_str).strip()\n",
    "    \n",
    "    # Timezone conversion map\n",
    "    tz_conversion = {\n",
    "        'EST': timezone('US/Eastern'),\n",
    "        'EDT': timezone('US/Eastern'),\n",
    "        'PST': timezone('US/Pacific'),\n",
    "        'PDT': timezone('US/Pacific'),\n",
    "        'GMT': timezone('GMT'),\n",
    "        'CET': timezone('CET'),\n",
    "        'MST': timezone('US/Mountain'),\n",
    "        'EET': timezone('EET'),\n",
    "        'JST': timezone('Asia/Tokyo')\n",
    "    }\n",
    "    \n",
    "    tz = 'EST'  # Default to EST\n",
    "    for tz_key in tz_conversion.keys():\n",
    "        if tz_key in date_str:\n",
    "            tz = tz_key\n",
    "            date_str = date_str.replace(tz_key, '').strip()\n",
    "            break\n",
    "    \n",
    "    # Remove redundant AM/PM indicators\n",
    "    date_str = date_str.replace('AM', ' AM').replace('PM', ' PM').strip()\n",
    "    \n",
    "    # Handle 24:xx hour format\n",
    "    if \"24:\" in date_str:\n",
    "        date_str = date_str.replace(\" 24:\", \" 00:\").strip()\n",
    "        add_day = True\n",
    "    else:\n",
    "        add_day = False\n",
    "    \n",
    "    # Handle different datetime formats\n",
    "    try:\n",
    "        naive_dt = datetime.strptime(date_str, \"%B %d, %Y %H:%M %p\")\n",
    "    except:\n",
    "        try:\n",
    "            naive_dt = datetime.strptime(date_str, \"%b %d, %Y\")\n",
    "        except:\n",
    "            try:\n",
    "                naive_dt = datetime.strptime(date_str, \"%B %d, %Y\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not convert to datetime: {date_str}, error: {e}\")\n",
    "                return None\n",
    "    \n",
    "    if add_day:\n",
    "        naive_dt += pd.Timedelta(days=1)\n",
    "    \n",
    "    # Convert to the specified timezone\n",
    "    localized_dt = tz_conversion[tz].localize(naive_dt)\n",
    "    est_dt = localized_dt.astimezone(timezone('US/Eastern'))\n",
    "    \n",
    "    return est_dt\n",
    "\n",
    "# Apply the function\n",
    "for df in [aapl_data, amzn_data, msft_data, nvidia_data]:\n",
    "    df['Datetime'] = df['Time_Published'].apply(convert_to_est_datetime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_data = aapl_data.drop(\"Cleaned_Date\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia_data = nvidia_data.sort_values(by='Datetime', ascending=True)\n",
    "aapl_data = aapl_data.sort_values(by='Datetime', ascending=True)\n",
    "amzn_data = amzn_data.sort_values(by='Datetime', ascending=True)\n",
    "amzn_data = amzn_data.sort_values(by='Datetime', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>Time_Published</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>343</td>\n",
       "      <td>Ponen en una laptop grabador de Blu-ray; Lanza...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>January 1, 2007 Monday</td>\n",
       "      <td>2007-01-01 00:00:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>341</td>\n",
       "      <td>Ponen en una laptop grabador de Blu-ray; Hogar...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>January 1, 2007 Monday</td>\n",
       "      <td>2007-01-01 00:00:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>185</td>\n",
       "      <td>LOOKING FORWARD: TECHNOLOGY TRENDS IN 2007</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>January 1, 2007 Monday</td>\n",
       "      <td>2007-01-01 00:00:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>Graphics chip co Lucid raises $12m; Intel Capi...</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>January 1, 2007 Monday</td>\n",
       "      <td>2007-01-01 00:00:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>Briefing.com: Tech Stocks</td>\n",
       "      <td>1.297297</td>\n",
       "      <td>January 1, 2007 Monday 11:55 AM EST</td>\n",
       "      <td>2007-01-01 11:55:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33327</th>\n",
       "      <td>33329</td>\n",
       "      <td>AMD, Nvidia Saw Market Share Rise in Q4 2010: ...</td>\n",
       "      <td>1.136364</td>\n",
       "      <td>January 31, 2011 Monday 01:04 PM GMT</td>\n",
       "      <td>2011-01-30 20:04:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33297</th>\n",
       "      <td>33299</td>\n",
       "      <td>NVIDIA (NVDA) Showing Bullish Technicals With ...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>January 31, 2011 Monday 8:53 AM EST</td>\n",
       "      <td>2011-01-31 08:53:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33402</th>\n",
       "      <td>33404</td>\n",
       "      <td>The Best Assistant to the Coming Motorola Xoom...</td>\n",
       "      <td>1.117647</td>\n",
       "      <td>January 31, 2011 Monday 9:08 AM EST</td>\n",
       "      <td>2011-01-31 09:08:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>2735</td>\n",
       "      <td>No Headline In Original</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>July 2, 2007 Issue</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6747</th>\n",
       "      <td>6747</td>\n",
       "      <td>No Headline In Original</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>June 2, 2008 Issue</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33435 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                              Title  \\\n",
       "343      343  Ponen en una laptop grabador de Blu-ray; Lanza...   \n",
       "341      341  Ponen en una laptop grabador de Blu-ray; Hogar...   \n",
       "185      185         LOOKING FORWARD: TECHNOLOGY TRENDS IN 2007   \n",
       "142      142  Graphics chip co Lucid raises $12m; Intel Capi...   \n",
       "166      166                          Briefing.com: Tech Stocks   \n",
       "...      ...                                                ...   \n",
       "33327  33329  AMD, Nvidia Saw Market Share Rise in Q4 2010: ...   \n",
       "33297  33299  NVIDIA (NVDA) Showing Bullish Technicals With ...   \n",
       "33402  33404  The Best Assistant to the Coming Motorola Xoom...   \n",
       "2735    2735                            No Headline In Original   \n",
       "6747    6747                            No Headline In Original   \n",
       "\n",
       "       Sentiment_Score                        Time_Published  \\\n",
       "343           1.000000                January 1, 2007 Monday   \n",
       "341           1.000000                January 1, 2007 Monday   \n",
       "185           1.071429                January 1, 2007 Monday   \n",
       "142           1.066667                January 1, 2007 Monday   \n",
       "166           1.297297   January 1, 2007 Monday 11:55 AM EST   \n",
       "...                ...                                   ...   \n",
       "33327         1.136364  January 31, 2011 Monday 01:04 PM GMT   \n",
       "33297         0.923077   January 31, 2011 Monday 8:53 AM EST   \n",
       "33402         1.117647   January 31, 2011 Monday 9:08 AM EST   \n",
       "2735          1.057143                    July 2, 2007 Issue   \n",
       "6747          1.000000                    June 2, 2008 Issue   \n",
       "\n",
       "                       Datetime  \n",
       "343   2007-01-01 00:00:00-05:00  \n",
       "341   2007-01-01 00:00:00-05:00  \n",
       "185   2007-01-01 00:00:00-05:00  \n",
       "142   2007-01-01 00:00:00-05:00  \n",
       "166   2007-01-01 11:55:00-05:00  \n",
       "...                         ...  \n",
       "33327 2011-01-30 20:04:00-05:00  \n",
       "33297 2011-01-31 08:53:00-05:00  \n",
       "33402 2011-01-31 09:08:00-05:00  \n",
       "2735                        NaT  \n",
       "6747                        NaT  \n",
       "\n",
       "[33435 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvidia_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_daily_sentiment(df):\n",
    "    df['Date'] = df['Datetime'].dt.date\n",
    "    \n",
    "    # Group by Date and average the Sentiment_Score\n",
    "    df_grouped = df.groupby('Date').agg({'Sentiment_Score': 'mean'}).reset_index()\n",
    "\n",
    "    df_grouped[\"Date\"] = pd.to_datetime(df_grouped[\"Date\"])\n",
    "    \n",
    "    return df_grouped\n",
    "\n",
    "aapl_data_grouped = average_daily_sentiment(aapl_data)\n",
    "amzn_data_grouped = average_daily_sentiment(amzn_data)\n",
    "msft_data_grouped = average_daily_sentiment(msft_data)\n",
    "nvidia_data_grouped = average_daily_sentiment(nvidia_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>1.061519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-02</td>\n",
       "      <td>1.118282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>1.051647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>1.020751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>0.879535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>2010-03-26</td>\n",
       "      <td>1.132178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>2010-03-28</td>\n",
       "      <td>1.060930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>2010-03-29</td>\n",
       "      <td>1.160856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>2010-03-30</td>\n",
       "      <td>0.979191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>0.987456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1172 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Sentiment_Score\n",
       "0    2007-01-01         1.061519\n",
       "1    2007-01-02         1.118282\n",
       "2    2007-01-03         1.051647\n",
       "3    2007-01-04         1.020751\n",
       "4    2007-01-05         0.879535\n",
       "...         ...              ...\n",
       "1167 2010-03-26         1.132178\n",
       "1168 2010-03-28         1.060930\n",
       "1169 2010-03-29         1.160856\n",
       "1170 2010-03-30         0.979191\n",
       "1171 2010-03-31         0.987456\n",
       "\n",
       "[1172 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_data_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df):\n",
    "    return df[(df['Date'] >= '2007-01-01') & (df['Date'] <= '2009-01-31')]\n",
    "\n",
    "aapl_data_filtered = filter_data(aapl_data_grouped)\n",
    "amzn_data_filtered = filter_data(amzn_data_grouped)\n",
    "msft_data_filtered = filter_data(msft_data_grouped)\n",
    "nvidia_data_filtered = filter_data(nvidia_data_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "                Open      High       Low     Close  Adj Close      Volume\n",
      "Date                                                                     \n",
      "2007-01-03  3.081786  3.092143  2.925000  2.992857   2.540327  1238319600\n",
      "2007-01-04  3.001786  3.069643  2.993571  3.059286   2.596712   847260400\n",
      "2007-01-05  3.063214  3.078571  3.014286  3.037500   2.578219   834741600\n",
      "2007-01-08  3.070000  3.090357  3.045714  3.052500   2.590951   797106800\n",
      "2007-01-09  3.087500  3.320714  3.041071  3.306071   2.806182  3349298400\n",
      "...              ...       ...       ...       ...        ...         ...\n",
      "2009-01-26  3.173571  3.248929  3.153571  3.201429   2.717361   692238400\n",
      "2009-01-27  3.221071  3.269643  3.205000  3.240357   2.750404   618038400\n",
      "2009-01-28  3.290000  3.392857  3.267857  3.364286   2.855594   861406000\n",
      "2009-01-29  3.324643  3.369286  3.307143  3.321429   2.819218   592729200\n",
      "2009-01-30  3.307143  3.343571  3.214643  3.218929   2.732216   651478800\n",
      "\n",
      "[524 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "tickers = [\"AAPL\", \"AMZN\", \"NVDA\", \"MSFT\"]\n",
    "start_date = \"2007-01-01\"\n",
    "end_date = \"2009-01-31\"\n",
    "\n",
    "stock_data = {}\n",
    "\n",
    "# Fetch the data\n",
    "for ticker in tickers:\n",
    "    stock_data[ticker] = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "print(stock_data[\"AAPL\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dates = set(stock_data[\"AAPL\"].index).intersection(\n",
    "    set(stock_data[\"AMZN\"].index),\n",
    "    set(stock_data[\"MSFT\"].index),\n",
    "    set(stock_data[\"NVDA\"].index)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_data_filtered = aapl_data_filtered[aapl_data_filtered['Date'].isin(common_dates)]\n",
    "amzn_data_filtered = amzn_data_filtered[amzn_data_filtered['Date'].isin(common_dates)]\n",
    "msft_data_filtered = msft_data_filtered[msft_data_filtered['Date'].isin(common_dates)]\n",
    "nvidia_data_filtered = nvidia_data_filtered[nvidia_data_filtered['Date'].isin(common_dates)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6z/_tfc4bdx6w7bg0w4vm5g0j5w0000gn/T/ipykernel_87473/2071334679.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  aapl_data_filtered['Price'] = aapl_data_filtered['Date'].map(stock_data[\"AAPL\"][\"Close\"])\n"
     ]
    }
   ],
   "source": [
    "aapl_data_filtered['Price'] = aapl_data_filtered['Date'].map(stock_data[\"AAPL\"][\"Close\"])\n",
    "amzn_data_filtered['Price'] = amzn_data_filtered['Date'].map(stock_data[\"AMZN\"][\"Close\"])\n",
    "msft_data_filtered['Price'] = msft_data_filtered['Date'].map(stock_data[\"MSFT\"][\"Close\"])\n",
    "nvidia_data_filtered['Price'] = nvidia_data_filtered['Date'].map(stock_data[\"NVDA\"][\"Close\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = amzn_data_filtered.merge(aapl_data_filtered, on='Date', suffixes=('_AMZN', '_AAPL'))\\\n",
    "                     .merge(msft_data_filtered, on='Date', suffixes=('', '_MSFT'))\\\n",
    "                     .merge(nvidia_data_filtered, on='Date', suffixes=('_MSFT', '_NVIDIA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"sentiment_and_prices.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
